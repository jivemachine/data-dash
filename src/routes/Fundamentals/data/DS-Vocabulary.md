---
 title: Data Science Vocabulary
 slug: DS-Vocabulary
 parent: Data-Science
---
    
    ## Foundational Vocabulary of Data Science
    
    **Algorithms** are a series of repeatable steps, usually expressed mathematically, to accomplish specific data science tasks or to solve a problem. Data scientists need to understand certain algorithms in so far as to be able to identify how appropriate an algorithm is for a particular problem as well as to be able to effectively select the values for the algorithm's hyperparameters. Commonly used algorithms in data science include linear and logistic regression, Naive Bayes, and KNN (K-Nearest Neighbors).
    
    **APIs**, application programming interfaces, provide users with a set of functions used to interact with and deploy the features of a specific application or service. As an example, Twitter provides access to Twitter features through its API. By hooking into the Twitter API, software developers can allow users of their own applications to log in using Twitter, or data scientists can access personal information stored in Twitter databases, such as handles of followers.
    
    **Artificial Intelligence (AI)** is about the creation of intelligent machines that work and react like humans. Examples of types of AI programs include speech recognition and self-driving cars.
    
    **Big data** is an evolving phrase. It is most commonly used to mean a massive volume of both structured and unstructured data that is so large it is difficult to process using traditional database and software techniques. The volume of data is too big, it moves too fast, or it exceeds current processing capacity. Often it is defined by the "4 V's": Volume, Velocity, Variety, and Veracity.
    
    **Data modeling** is building mathematical or statistical models that turn data into predictive and actionable information, that can predict and explain outcomes.
    
    **Data science** is a field that works with and analyzes large amounts of data to provide meaningful information that can be used to make decisions and solve problems. Data science includes work in computation, statistics, analytics, data mining, and programming.
    
    **Data visualization** has two primary purposes: 1) to explore data and understand the meaning behind it or 2) to communicate to others (such as an idea, a finding, a recommendation, or a story).
    
    **Deep learning** is a subset of machine learning that uses neural network algorithms for problems such as speech recognition, translation, and image recognition.
    
    **Feature engineering** is the process of using domain knowledge of the data to create features that make machine learning algorithms work. Feature engineering is fundamental to the application and success of machine learning.
    
    **Machine learning** enables computers predict outcomes without explicit human input.
    
    A **model hyperparameter** is a configuration that is external to the specific model. The value is not estimated from data. Hyperparameters are used to customize the algorithm for a given problem so that it can more effectively estimate model parameters. They are usually manually specified when creating the model object. Examples of model hyperparameters include the number of decision trees in a random forest and the k in k-nearest neighbors.
    
    A **model parameter** is a configuration variable that is internal to the model. The values are estimated or learned from data when the model is being 'fit'. They are the part of the model that is learned from historical training data. The parameters customize the model to your particular problem so that you can then predict outcomes on new observations. They are saved as part of the learned model. Examples include: the split points of a decision tree, the support vectors in a support vector machine, the coefficients in a linear regression or logistic regression.
    
    **Reinforcement learning** is a subset of unsupervised machine learning where the machine seeks to maximize reward. The machine, or “agent,” learns through trial and error as well as reward and punishment. For example, if you are training a machine to win at chess, you would want it to be positively reinforced when it makes moves that win material, such as capturing a pawn, and negatively reinforced when it makes moves that lose material, such as having a pawn captured. Combinations of these rewards and punishments result in a self-learning machine that improves at chess over time.
    
    **Supervised machine learning** algorithms use labeled observations, i.e. observations with a known outcome or human input, to develop a model that will then be used to predict or estimate the outcome of new observations which are not known or labeled.
    
    **Unstructured data** is that which does not fit a predefined data model. Often this data does not fit into the typical row-column structure of a database. Images, emails, videos, audio, and pretty much anything else that might be difficult to “tabify” might constitute examples of unstructured data.
    
    **Unsupervised machine learning** algorithms are considered self-learning as they not rely on labeled observations, i.e. observations with a known outcome or human input. Whereas the supervised algorithm would accept and use the labels assigned to it to model the relationship between the inputs (features) and output (target), an unsupervised algorithm would learn the differences of observations using only the features (no output) and assign its own labels to differentiate.